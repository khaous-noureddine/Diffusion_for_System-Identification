{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72433dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "from jit_model import JiTFluidDiffusion\n",
    "from jit_engine import train_jit_diffusion, evaluate_autoregressive, create_comparison_video\n",
    "from jit_data import (split_data, \n",
    "                      compute_normalization_stats, \n",
    "                      normalize_data_list, \n",
    "                      create_jit_sequences,\n",
    "                      FluidDynamicsDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba3ea9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"toto\"\n",
    "img_size = 48\n",
    "delta_t = 1.0\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "067d7696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Using device: cuda\n",
      "‚úì File found: /home/nkhaous/myLLF/JiT_SysId/data/oscillating_cylinder_benchmark_dataset_v2.mat\n",
      "\n",
      "=== Loading data ===\n",
      "Train: 6, Val: 3, Test: 2\n",
      "\n",
      "=== Normalization ===\n",
      "Frame: Œº=0.001842, œÉ=14.864110\n",
      "Control u: Œº=-0.000000, œÉ=0.012448\n",
      "\n",
      "=== Creating sequences ===\n",
      "Train sequences: 9060, Val sequences: 4530\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "##### Data Preparation ##### \n",
    "############################\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üöÄ Using device: {device}\")\n",
    "\n",
    "file_path = \"/home/nkhaous/myLLF/JiT_SysId/data/oscillating_cylinder_benchmark_dataset_v2.mat\"\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"‚ùå File not found: {file_path}\")\n",
    "    for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "        for file in files:\n",
    "            print(os.path.join(root, file))\n",
    "    exit()\n",
    "\n",
    "print(f\"‚úì File found: {file_path}\")\n",
    "\n",
    "# Load data\n",
    "print(\"\\n=== Loading data ===\")\n",
    "train_list, val_list, test_list = split_data(file_path)\n",
    "print(f\"Train: {len(train_list)}, Val: {len(val_list)}, Test: {len(test_list)}\")\n",
    "\n",
    "# Normalize\n",
    "print(\"\\n=== Normalization ===\")\n",
    "frame_mean, frame_std, u_mean, u_std = compute_normalization_stats(train_list)\n",
    "print(f\"Frame: Œº={frame_mean:.6f}, œÉ={frame_std:.6f}\")\n",
    "print(f\"Control u: Œº={u_mean:.6f}, œÉ={u_std:.6f}\")\n",
    "\n",
    "\n",
    "normalize_data_list(train_list, frame_mean, frame_std, u_mean, u_std)\n",
    "normalize_data_list(val_list, frame_mean, frame_std, u_mean, u_std)\n",
    "normalize_data_list(test_list, frame_mean, frame_std, u_mean, u_std)\n",
    "\n",
    "# Create sequences\n",
    "print(\"\\n=== Creating sequences ===\")\n",
    "past_window = 10\n",
    "X_train_frames, X_train_u_past, X_train_u_curr, Y_train = create_jit_sequences(train_list, past_window)\n",
    "X_val_frames, X_val_u_past, X_val_u_curr, Y_val = create_jit_sequences(val_list, past_window)\n",
    "print(f\"Train sequences: {X_train_frames.shape[0]}, Val sequences: {X_val_frames.shape[0]}\")\n",
    "\n",
    "# DataLoaders\n",
    "train_dataset = FluidDynamicsDataset(X_train_frames, X_train_u_past, X_train_u_curr, Y_train)\n",
    "val_dataset = FluidDynamicsDataset(X_val_frames, X_val_u_past, X_val_u_curr, Y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2374ff8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Creating JiT model ===\n",
      "Total parameters: 32,963,712\n",
      "Trainable parameters: 32,960,256\n",
      "\n",
      "=== Training JiT Fluid Diffusion ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 [Train]:   0%|          | 0/284 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (9) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m models_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput/exp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/models\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(models_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 38\u001b[0m \u001b[43mtrain_jit_diffusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_jit_fluid_model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/myLLF/JiT_SysId/jit_engine.py:32\u001b[0m, in \u001b[0;36mtrain_jit_diffusion\u001b[0;34m(model, train_loader, val_loader, num_epochs, device, learning_rate, best_model_path)\u001b[0m\n\u001b[1;32m     29\u001b[0m target_frame \u001b[38;5;241m=\u001b[39m target_frame\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 32\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_u_past\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_u_curr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/jit/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jit/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/myLLF/JiT_SysId/jit_model.py:350\u001b[0m, in \u001b[0;36mJiTFluidDiffusion.forward\u001b[0;34m(self, cond_frames, cond_u_past, cond_u_curr, target_frame)\u001b[0m\n\u001b[1;32m    346\u001b[0m x_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_embedder(z_t)  \u001b[38;5;66;03m# (B, num_patches, hidden_size)\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# Combine conditioning and noisy target tokens\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;66;03m# Simple approach: add them\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43mx_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcond_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_embed\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# Time and control embedding\u001b[39;00m\n\u001b[1;32m    353\u001b[0m t_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_embedder(t_flat)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (9) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "############################\n",
    "###### Model Training ######\n",
    "############################\n",
    "\n",
    "# Create model\n",
    "print(\"\\n=== Creating JiT model ===\")\n",
    "model = JiTFluidDiffusion(\n",
    "    img_size=img_size,\n",
    "    patch_size=16,\n",
    "    in_channels=1,\n",
    "    past_window=past_window,\n",
    "    hidden_size=384,\n",
    "    depth=12,\n",
    "    num_heads=6,\n",
    "    mlp_ratio=4.0,\n",
    "    bottleneck_dim=64,\n",
    "    diffusion_steps=50,\n",
    "    P_mean=-0.8,\n",
    "    P_std=0.8,\n",
    "    t_eps=0.05,\n",
    "    noise_scale=1.0\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Train\n",
    "print(\"\\n=== Training JiT Fluid Diffusion ===\")\n",
    "num_epochs = 1\n",
    "\n",
    "models_path = f\"output/exp_{exp_name}/models\"\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "\n",
    "train_jit_diffusion(model, train_loader, val_loader, num_epochs, device, learning_rate=2e-4, best_model_path=os.path.join(models_path, \"best_jit_fluid_model.pth\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "##### Model Evaluation #####\n",
    "############################\n",
    "# Evaluate\n",
    "print(\"\\n=== Evaluation on test set ===\")\n",
    "model.load_state_dict(torch.load(f\"output/exp_{exp_name}/models/best_jit_fluid_model.pth\"))\n",
    "\n",
    "total_mse = 0\n",
    "for i, test_case in enumerate(test_list):\n",
    "    print(f\"\\nüìä Test case {i+1}/{len(test_list)} (amplitude: {test_case['amplitude']})\")\n",
    "    pred_frames, true_frames, mse = evaluate_autoregressive(\n",
    "        model, test_case, past_window, device, num_frames=20, \n",
    "        frame_mean=frame_mean, frame_std=frame_std, num_steps=50 \n",
    "    )\n",
    "    total_mse += mse\n",
    "    \n",
    "    # Video\n",
    "    gt_seq = true_frames.squeeze(1)\n",
    "    pred_seq = pred_frames.squeeze(1)\n",
    "    video_path = f\"output/exp_{exp_name}/videos\"\n",
    "    os.makedirs(video_path, exist_ok=True)\n",
    "    create_comparison_video(gt_seq, pred_seq, test_case['amplitude'], save_path=os.path.join(video_path, f\"jit_comparison_{test_case['amplitude']}.gif\"))\n",
    "\n",
    "avg_test_mse = total_mse / len(test_list)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ Average test MSE: {avg_test_mse:.6f}\")\n",
    "print(f\"{'='*60}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
