{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T16:02:15.491601Z",
     "iopub.status.busy": "2026-01-20T16:02:15.491177Z",
     "iopub.status.idle": "2026-01-20T16:02:16.638469Z",
     "shell.execute_reply": "2026-01-20T16:02:16.637175Z",
     "shell.execute_reply.started": "2026-01-20T16:02:15.491561Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, SubsetRandomSampler\n",
    "import copy\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:23:40.066428Z",
     "iopub.status.busy": "2026-01-20T13:23:40.066033Z",
     "iopub.status.idle": "2026-01-20T13:23:40.313508Z",
     "shell.execute_reply": "2026-01-20T13:23:40.312409Z",
     "shell.execute_reply.started": "2026-01-20T13:23:40.066394Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DataParams(object):\n",
    "    def __init__(self, batch=4, augmentations=[], sequenceLength=[1,1], randSeqOffset=False,\n",
    "                dataSize=[128,64], dimension=2, simFields=[], simParams=[], normalizeMode=\"\"):\n",
    "        self.batch          = batch             # batch size\n",
    "        self.augmentations  = augmentations     # used data augmentations\n",
    "        self.sequenceLength = sequenceLength    # number of simulation frames in one sequence\n",
    "        self.randSeqOffset  = randSeqOffset     # randomize sequence starting frame\n",
    "        self.dataSize       = dataSize          # target data size for scale/crop/cropRandom transformation\n",
    "        self.dimension      = dimension         # number of data dimension\n",
    "        self.simFields      = simFields         # which simulation fields are added (vel is always used) from [\"dens\", \"pres\"]\n",
    "        self.simParams      = simParams         # which simulation parameters are added from [\"rey\", \"mach\"]\n",
    "        self.normalizeMode  = normalizeMode     # which mean and std values from different data sets are used in normalization transformation\n",
    "\n",
    "    @classmethod\n",
    "    def fromDict(cls, d:dict):\n",
    "        p = cls()\n",
    "        p.batch          = d.get(\"batch\",            -1)\n",
    "        p.augmentations  = d.get(\"augmentations\",    [])\n",
    "        p.sequenceLength = d.get(\"sequenceLength\",   [])\n",
    "        p.randSeqOffset  = d.get(\"randSeqOffset\",    False)\n",
    "        p.dataSize       = d.get(\"dataSize\",         -1)\n",
    "        p.dimension      = d.get(\"dimension\",        -1)\n",
    "        p.simFields      = d.get(\"simFields\",        [])\n",
    "        p.simParams      = d.get(\"simParams\",        [])\n",
    "        p.normalizeMode  = d.get(\"normalizeMode\",    \"\")\n",
    "        return p\n",
    "\n",
    "    def asDict(self) -> dict:\n",
    "        return {\n",
    "            \"batch\"          : self.batch,\n",
    "            \"augmentations\"  : self.augmentations,\n",
    "            \"sequenceLength\" : self.sequenceLength,\n",
    "            \"randSeqOffset\"  : self.randSeqOffset,\n",
    "            \"dataSize\"       : self.dataSize,\n",
    "            \"dimension\"      : self.dimension,\n",
    "            \"simFields\"      : self.simFields,\n",
    "            \"simParams\"      : self.simParams,\n",
    "            \"normalizeMode\"  : self.normalizeMode,\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "class TrainingParams(object):\n",
    "    def __init__(self, epochs=20, lr=0.0001, expLrGamma=1.0, weightDecay=0.0, fadeInPredLoss=[-1,0], fadeInSeqLen=[-1,0], fadeInSeqLenLin=False):\n",
    "        self.epochs            = epochs            # number of training epochs\n",
    "        self.lr                = lr                # learning rate\n",
    "        self.expLrGamma        = expLrGamma        # factor for exponential learning rate decay\n",
    "        self.weightDecay       = weightDecay       # weight decay factor to regularize the net by penalizing large weights\n",
    "        self.fadeInPredLoss    = fadeInPredLoss    # start and end epoch of fading in the prediction loss terms\n",
    "        self.fadeInSeqLen      = fadeInSeqLen      # start and end epoch of fading in the sequence length\n",
    "        self.fadeInSeqLenLin   = fadeInSeqLenLin   # exponential or linear scaling of fading in the sequence length\n",
    "        \n",
    "    @classmethod\n",
    "    def fromDict(cls, d:dict):\n",
    "        p = cls()\n",
    "        p.epochs            = d.get(\"epochs\",           -1)\n",
    "        p.lr                = d.get(\"lr\",               -1)\n",
    "        p.expLrGamma        = d.get(\"expLrGamma\",        1)\n",
    "        p.weightDecay       = d.get(\"weightDecay\",      -1)\n",
    "        p.fadeInPredLoss    = d.get(\"fadeInPredLoss\",   [])\n",
    "        p.fadeInSeqLen      = d.get(\"fadeInSeqLen\",     [])\n",
    "        p.fadeInSeqLenLin   = d.get(\"fadeInSeqLenLin\",  False)\n",
    "        return p\n",
    "\n",
    "    def asDict(self) -> dict:\n",
    "        return {\n",
    "            \"epochs\"            : self.epochs,\n",
    "            \"lr\"                : self.lr,\n",
    "            \"expLrGamma\"        : self.expLrGamma,\n",
    "            \"weightDecay\"       : self.weightDecay,\n",
    "            \"fadeInPredLoss\"    : self.fadeInPredLoss,\n",
    "            \"fadeInSeqLen\"      : self.fadeInSeqLen,\n",
    "            \"fadeInSeqLenLin\"   : self.fadeInSeqLenLin,\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "class LossParams(object):\n",
    "    def __init__(self, recMSE=1.0, recLSIM=0, predMSE=1.0, predLSIM=0, extraMSEvelZ=0, regMeanStd=0, regDiv=0, regVae=0, regLatStep=0):\n",
    "        self.recMSE       = recMSE       # mse loss reconstruction weight\n",
    "        self.recLSIM      = recLSIM      # lsim loss reconstruction weight\n",
    "        self.predMSE      = predMSE      # mse loss prediction weight\n",
    "        self.predLSIM     = predLSIM     # lsim loss prediction weight\n",
    "        self.regMeanStd   = regMeanStd   # mean and standard deviation regularization weight\n",
    "        self.regDiv       = regDiv       # divergence regularization weight\n",
    "        self.regVae       = regVae       # regularization weight for VAE KL divergence\n",
    "        self.regLatStep   = regLatStep   # latent space step regularization weight\n",
    "\n",
    "    @classmethod\n",
    "    def fromDict(cls, d:dict):\n",
    "        p = cls()\n",
    "        p.recMSE       = d.get(\"recMSE\", -1)\n",
    "        p.recLSIM      = d.get(\"recLSIM\", -1)\n",
    "        p.predMSE      = d.get(\"predMSE\", -1)\n",
    "        p.predLSIM     = d.get(\"predLSIM\", -1)\n",
    "        p.regMeanStd   = d.get(\"regMeanStd\", -1)\n",
    "        p.regDiv       = d.get(\"regDiv\", -1)\n",
    "        p.regVae       = d.get(\"regVae\", -1)\n",
    "        p.regLatStep   = d.get(\"regLatStep\", -1)\n",
    "        return p\n",
    "\n",
    "    def asDict(self) -> dict:\n",
    "        return {\n",
    "            \"recMSE\"       : self.recMSE,\n",
    "            \"recLSIM\"      : self.recLSIM,\n",
    "            \"predMSE\"      : self.predMSE,\n",
    "            \"predLSIM\"     : self.predLSIM,\n",
    "            \"regMeanStd\"   : self.regMeanStd,\n",
    "            \"regDiv\"       : self.regDiv,\n",
    "            \"regVae\"       : self.regVae,\n",
    "            \"regLatStep\"   : self.regLatStep,\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "class ModelParamsEncoder(object):\n",
    "    def __init__(self, arch=\"skip\", pretrained=False, frozen=False, encWidth=16, latentSize=16):\n",
    "        self.arch = arch              # architecture variant\n",
    "        self.pretrained = pretrained  # load pretrained weight initialization\n",
    "        self.frozen = frozen          # freeze weights after initialization\n",
    "        self.encWidth = encWidth      # width of encoder network\n",
    "        self.latentSize = latentSize  # size of latent space vector\n",
    "\n",
    "    @classmethod\n",
    "    def fromDict(cls, d:dict):\n",
    "        p = cls()\n",
    "        p.arch       = d.get(\"arch\", \"\")\n",
    "        p.pretrained = d.get(\"pretrained\", False)\n",
    "        p.frozen     = d.get(\"frozen\", False)\n",
    "        p.encWidth   = d.get(\"encWidth\", -1)\n",
    "        p.latentSize = d.get(\"latentSize\", -1)\n",
    "        return p\n",
    "\n",
    "    def asDict(self) -> dict:\n",
    "        return {\n",
    "            \"arch\"       : self.arch,\n",
    "            \"pretrained\" : self.pretrained,\n",
    "            \"frozen\"     : self.frozen,\n",
    "            \"encWidth\"   : self.encWidth,\n",
    "            \"latentSize\" : self.latentSize,\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "class ModelParamsDecoder(object):\n",
    "    def __init__(self, arch=\"skip\", pretrained=False, frozen=False, decWidth=48, vae=False, trainingNoise=0.0,\n",
    "                 diffSteps=500, diffSchedule=\"linear\", diffCondIntegration=\"noisy\", fnoModes=(16,16), refinerStd=0.0):\n",
    "        self.arch = arch                 # architecture variant\n",
    "        self.pretrained = pretrained     # load pretrained weight initialization\n",
    "        self.frozen = frozen             # freeze weights after initialization\n",
    "        self.decWidth = decWidth         # width of decoder network\n",
    "        self.vae = vae                   # use a variational AE setup\n",
    "        self.trainingNoise = trainingNoise # amount of training noise added to inputs\n",
    "        self.diffSteps = diffSteps       # diffusion model diffusion time steps\n",
    "        self.diffSchedule = diffSchedule # diffusion model variance schedule\n",
    "        self.diffCondIntegration = diffCondIntegration # integrationg of conditioning during diffusion training\n",
    "        self.fnoModes = fnoModes         # number of fourier modes for FNO setup\n",
    "        self.refinerStd = refinerStd     # noise standard dev. in pde refiner setup\n",
    "\n",
    "    @classmethod\n",
    "    def fromDict(cls, d:dict):\n",
    "        p = cls()\n",
    "        p.arch         = d.get(\"arch\", \"\")\n",
    "        p.pretrained   = d.get(\"pretrained\", False)\n",
    "        p.frozen       = d.get(\"frozen\", False)\n",
    "        p.decWidth     = d.get(\"decWidth\", -1)\n",
    "        p.vae          = d.get(\"vae\", False)\n",
    "        p.trainingNoise= d.get(\"trainingNoise\", 0.0)\n",
    "        p.diffSteps    = d.get(\"diffSteps\", 500)\n",
    "        p.diffSchedule = d.get(\"diffSchedule\", \"linear\")\n",
    "        p.diffCondIntegration  = d.get(\"diffCondIntegration\", \"noisy\")\n",
    "        p.fnoModes     = d.get(\"fnoModes\", ())\n",
    "        p.refinerStd   = d.get(\"refinerStd\", 0.0)\n",
    "        return p\n",
    "\n",
    "    def asDict(self) -> dict:\n",
    "        return {\n",
    "            \"arch\"         : self.arch,\n",
    "            \"pretrained\"   : self.pretrained,\n",
    "            \"frozen\"       : self.frozen,\n",
    "            \"decWidth\"     : self.decWidth,\n",
    "            \"vae\"          : self.vae,\n",
    "            \"trainingNoise\": self.trainingNoise,\n",
    "            \"diffSteps\"    : self.diffSteps,\n",
    "            \"diffSchedule\" : self.diffSchedule,\n",
    "            \"diffCondIntegration\" : self.diffCondIntegration,\n",
    "            \"fnoModes\"     : self.fnoModes,\n",
    "            \"refinerStd\"   : self.refinerStd,\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "class ModelParamsLatent(object):\n",
    "    def __init__(self, arch=\"fc\", pretrained=False, frozen=False, width=512, layers=6, heads=4, dropout=0.0,\n",
    "               transTrainUnroll=False, transTargetFull=False, maxInputLen=-1):\n",
    "        self.arch = arch                         # architecture variant\n",
    "        self.pretrained = pretrained             # load pretrained weight initialization\n",
    "        self.frozen = frozen                     # freeze weights after initialization\n",
    "        self.width = width                       # latent network width\n",
    "        self.layers = layers                     # number of latent network layers\n",
    "        self.heads = heads                       # number of attention heads in transformer\n",
    "        self.dropout = dropout                   # dropout rate in latent network\n",
    "        self.transTrainUnroll = transTrainUnroll # unrolled training for transformer latent models, FALSE for one step predictions TRUE for full rollouts\n",
    "        self.transTargetFull = transTargetFull   # full target data for transformer and transformer decoder latent models, FALSE for only the previous step as a target TRUE for every previous step as a target\n",
    "        self.maxInputLen = maxInputLen           # how many steps of the input sequence are processed at once for models that predict full sequences (-1 for no limit)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def fromDict(cls, d:dict):\n",
    "        p = cls()\n",
    "        p.arch             = d.get(\"arch\", \"\")\n",
    "        p.pretrained       = d.get(\"pretrained\", False)\n",
    "        p.frozen           = d.get(\"frozen\", False)\n",
    "        p.width            = d.get(\"width\", \"\")\n",
    "        p.layers           = d.get(\"layers\", \"\")\n",
    "        p.heads            = d.get(\"heads\", \"\")\n",
    "        p.dropout          = d.get(\"dropout\", \"\")\n",
    "        p.transTrainUnroll = d.get(\"transTrainUnroll\", False)\n",
    "        p.transTargetFull  = d.get(\"transTargetFull\", False)\n",
    "        p.maxInputLen      = d.get(\"maxInputLen\", -1)\n",
    "        return p\n",
    "\n",
    "    def asDict(self) -> dict:\n",
    "        return {\n",
    "            \"arch\"             : self.arch,\n",
    "            \"pretrained\"       : self.pretrained,\n",
    "            \"frozen\"           : self.frozen,\n",
    "            \"width\"            : self.width,\n",
    "            \"layers\"           : self.layers,\n",
    "            \"heads\"            : self.heads,\n",
    "            \"dropout\"          : self.dropout,\n",
    "            \"transTrainUnroll\" : self.transTrainUnroll,\n",
    "            \"transTargetFull\"  : self.transTargetFull,\n",
    "            \"maxInputLen\"      : self.maxInputLen,\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Transforms(object):\n",
    "    p_d: DataParams\n",
    "\n",
    "    def __init__(self, p_d:DataParams):\n",
    "\n",
    "        assert all(aug in [\"normalize\", \"flip\", \"crop\", \"resize\"]\n",
    "                        for aug in p_d.augmentations), \"Invalid augmentation provided!\"\n",
    "        assert not (\"crop\" in p_d.augmentations and \"resize\" in p_d.augmentations\n",
    "                        ), \"Crop and resize augmentation not allowed at the same time!\"\n",
    "        assert (p_d.normalizeMode != \"\"), \"Invalid normalization mode!\"\n",
    "\n",
    "        self.p_d = p_d\n",
    "        self.normalize = \"normalize\" in p_d.augmentations\n",
    "        self.flip = \"flip\" in p_d.augmentations\n",
    "        self.crop = \"crop\" in p_d.augmentations\n",
    "        self.resize = \"resize\" in p_d.augmentations\n",
    "        self.outputSize = p_d.dataSize\n",
    "        self.dim = p_d.dimension\n",
    "        self.simFields = p_d.simFields\n",
    "        self.simParams = p_d.simParams\n",
    "\n",
    "        # mean and std statistics from whole dataset for normalization\n",
    "        if self.dim == 2:\n",
    "            l = self.p_d.normalizeMode.lower()\n",
    "            if (\"inc\" in l and \"mixed\" in l) or (\"karman\" in l and \"mixed\" in l):\n",
    "                # ORDER (fields): velocity (x,y), --, pressure, ORDER (params): rey, --, --\n",
    "                self.normMean = np.array([0.444969, 0.000299, 0, 0.000586, 550.000000, 0, 0], dtype=np.float32)\n",
    "                self.normStd =  np.array([0.206128, 0.206128, 1, 0.003942, 262.678467, 1, 1], dtype=np.float32)\n",
    "\n",
    "            if (\"tra\" in l and \"mixed\" in l) or (\"mach\" in l and \"mixed\" in l):\n",
    "                # ORDER (fields): velocity (x,y), density, pressure, ORDER (params): rey, mach, --\n",
    "                self.normMean = np.array([0.560642, -0.000129, 0.903352, 0.637941, 10000.000000, 0.700000, 0], dtype=np.float32)\n",
    "                self.normStd =  np.array([0.216987, 0.216987, 0.145391, 0.119944, 1, 0.118322, 1], dtype=np.float32)\n",
    "\n",
    "            if \"iso\" in l and \"single\" in l:\n",
    "                # ORDER (fields): velocity (x,y,z), pressure, ORDER (params): --, --, --\n",
    "                self.normMean = np.array([-0.054618, -0.385225, -0.255757, 0.033446, 0, 0, 0], dtype=np.float32)\n",
    "                self.normStd =  np.array([0.539194, 0.710318, 0.510352, 0.258235, 1, 1, 1], dtype=np.float32)\n",
    "\n",
    "        # seeding once for single thread data loading\n",
    "        self.randGen = np.random.RandomState(torch.random.initial_seed() % 4294967295)\n",
    "\n",
    "\n",
    "    def __call__(self, sample:dict):\n",
    "        # seeding in every call for multi thread data loading\n",
    "        if torch.utils.data.get_worker_info():\n",
    "            self.randGen = np.random.RandomState(torch.utils.data.get_worker_info().seed % 4294967295)\n",
    "\n",
    "        data = sample[\"data\"]\n",
    "        simParameters = sample[\"simParameters\"]\n",
    "        allParameters = sample[\"allParameters\"]\n",
    "        obsMask = sample.get(\"obsMask\", None)\n",
    "        path = sample[\"path\"]\n",
    "\n",
    "        # normalization to std. normal distr. with zero mean and unit std via statistics from whole dataset\n",
    "        # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice\n",
    "        if self.normalize:\n",
    "            filterList = [0, 1] if self.dim == 2 else [0, 1, 2]\n",
    "            if \"dens\" in self.simFields or \"velZ\" in self.simFields:\n",
    "                filterList += [2] if self.dim == 2 else [3]\n",
    "            if \"pres\" in self.simFields:\n",
    "                filterList += [3] if self.dim == 2 else [4]\n",
    "            if \"rey\" in self.simParams:\n",
    "                filterList += [4] if self.dim == 2 else [5]\n",
    "            if \"mach\" in self.simParams:\n",
    "                filterList += [5] if self.dim == 2 else [6]\n",
    "            if \"zslice\" in self.simParams:\n",
    "                filterList += [6] if self.dim == 2 else [7]\n",
    "            filterArr = np.array(filterList)\n",
    "            filterArrParam = filterArr[-len(self.simParams):]\n",
    "\n",
    "            if self.simParams:\n",
    "                meanParam = self.normMean[filterArrParam].reshape((1,-1))\n",
    "                stdParam = self.normStd[filterArrParam].reshape((1,-1))\n",
    "                simParameters = (simParameters - meanParam) / stdParam\n",
    "\n",
    "            meanData = self.normMean[filterArr].reshape((1,-1,1,1)) if self.dim == 2 else self.normMean[filterArr].reshape((1,-1,1,1,1))\n",
    "            stdData = self.normStd[filterArr].reshape((1,-1,1,1)) if self.dim == 2 else self.normStd[filterArr].reshape((1,-1,1,1,1))\n",
    "            if self.dim == 2:\n",
    "                data = (data - meanData) / stdData\n",
    "            elif self.dim == 3:\n",
    "                data = (data - meanData) / stdData\n",
    "\n",
    "        # random flip\n",
    "        if self.flip:\n",
    "            if self.dim == 2:\n",
    "                rand = self.randGen.rand(2) > 0.5\n",
    "                flipped = False\n",
    "                if rand[0]:\n",
    "                    data = np.flip(data, axis=2)\n",
    "                    flipped = True\n",
    "                if rand[1]:\n",
    "                    data = np.flip(data, axis=3)\n",
    "                    flipped = True\n",
    "                if flipped:\n",
    "                    data = data.copy() #prevent negative strides that has issues with torch tensor creation\n",
    "            if self.dim == 3:\n",
    "                raise NotImplementedError(\"Flip augmentation not supported for 3D yet!\")\n",
    "\n",
    "        # random crop\n",
    "        if self.crop:\n",
    "            if self.dim == 2:\n",
    "                s = self.outputSize\n",
    "                if data.shape[2] > s[0] or data.shape[3] > s[1]:\n",
    "                    c1 = self.randGen.randint(0, data.shape[2] - s[0]+1)\n",
    "                    c2 = self.randGen.randint(0, data.shape[3] - s[1]+1)\n",
    "                    data = data[..., c1:c1+s[0], c2:c2+s[1]]\n",
    "            if self.dim == 3:\n",
    "                raise NotImplementedError(\"Crop augmentation not supported for 3D yet!\")\n",
    "\n",
    "        # toTensor\n",
    "        result = torch.from_numpy(data)\n",
    "        if obsMask is not None:\n",
    "            obsMask = torch.from_numpy(obsMask)\n",
    "\n",
    "        # resize\n",
    "        if self.resize:\n",
    "            result = F.interpolate(result, self.outputSize, mode=\"bilinear\", align_corners=True)\n",
    "            if obsMask is not None:\n",
    "                obsMask = F.interpolate(obsMask, self.outputSize, mode=\"nearest\", align_corners=True)\n",
    "\n",
    "        outDict = {\"data\": result, \"simParameters\": simParameters, \"allParameters\": allParameters, \"path\": path}\n",
    "        if obsMask is not None:\n",
    "            outDict[\"obsMask\"] = obsMask\n",
    "        return outDict\n",
    "    \n",
    "    \n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import os, json\n",
    "import logging\n",
    "from typing import List,Tuple\n",
    "\n",
    "# from turbpred.data_transformations import Transforms\n",
    "\n",
    "\n",
    "class TurbulenceDataset(Dataset):\n",
    "    \"\"\"Data set for turbulence and wavelet noise data\n",
    "\n",
    "    Args:\n",
    "        name: name of the dataset\n",
    "        dataDirs: list of paths to data directories\n",
    "        filterTop: filter for top level folder names (e.g. different types of data)\n",
    "        excludeFilterTop: mode for filterTop (exclude or include)\n",
    "        filterSim: filter simulations by min and max (min inclusive, max exclusive)\n",
    "        excludefilterSim: mode for filterSim (exclude or include)\n",
    "        filterFrame: mandatory filter for simulation frames by min and max (min inclusive, max exclusive)\n",
    "        sequenceLength: number of frames to group into a sequence and number of frames to omit in between\n",
    "        randSeqOffset: randomizes the starting frame of each sequence\n",
    "        simFields: list of simulation fields to include (vel is always included) [\"dens\", \"pres\"]\n",
    "        simParams: list of simulation parameters to include [\"rey\", \"mach\"]\n",
    "        printLevel: print mode for contents of the dataset [\"none\", \"top\", \"sim\", \"full\"]\n",
    "        logLevel: log mode for contents of the dataset [\"none\", \"top\", \"sim\", \"full\"]\n",
    "    \"\"\"\n",
    "    transform: Transforms\n",
    "    name:str\n",
    "    dataDirs:List[str]\n",
    "    filterTop:List[str]\n",
    "    excludeFilterTop:bool\n",
    "    filterSim:List[Tuple[int, int]]\n",
    "    excludefilterSim:bool\n",
    "    filterFrame:List[Tuple[int, int]]\n",
    "    sequenceLength:List[Tuple[int, int]]\n",
    "    randSeqOffset:bool\n",
    "    simFields:List[str]\n",
    "    simParams:List[str]\n",
    "    printLevel:str=\"none\"\n",
    "    logLevel:str=\"sim\"\n",
    "\n",
    "    def __init__(self, name:str, dataDirs:List[str], filterTop:List[str], excludeFilterTop:bool=False, filterSim:List[Tuple[int, int]]=[],\n",
    "                excludefilterSim:bool=False, filterFrame:List[Tuple[int, int]]=[], sequenceLength:List[Tuple[int, int]]=[],\n",
    "                randSeqOffset:bool=False, simFields:List[str]=[], simParams:List[str]=[], printLevel:str=\"none\", logLevel:str=\"sim\"):\n",
    "\n",
    "        assert (len(filterSim) in [0,1,len(filterTop)]), \"Sim filter is not set up correctly. Use len=0 for all; len=1 for the same everywhere, len=len(filterTop) to adjust for each top filter\"\n",
    "        assert (len(filterFrame) in [1,len(filterTop)]), \"Frame filter is not set up correctly. Use len=1 for the same everywhere, len=len(filterTop) to adjust for each top filter\"\n",
    "        assert (len(sequenceLength) == len(filterFrame)), \"Sequence length is not set up correctly, it should match the frame filter.\"\n",
    "        if excludeFilterTop:\n",
    "            assert (len(filterSim) <= 1), \"Excluded top filter and adjust sim filtering is not supported!\"\n",
    "            assert (len(filterFrame) <= 1), \"Excluded top filter and adjust frame filtering is not supported!\"\n",
    "        assert (printLevel in [\"none\", \"top\", \"sim\", \"full\"]), \"Invalid print level!\"\n",
    "\n",
    "        self.transform = None\n",
    "        self.name = name\n",
    "        self.dataDirs = dataDirs\n",
    "        self.filterTop = filterTop\n",
    "        self.excludeFilterTop = excludeFilterTop\n",
    "        self.filterSim = filterSim\n",
    "        self.excludefilterSim = excludefilterSim\n",
    "        self.filterFrame = filterFrame\n",
    "        self.sequenceLength = sequenceLength\n",
    "        self.randSeqOffset = randSeqOffset\n",
    "        self.simFields = [\"velocity\"]\n",
    "        if \"velZ\" in simFields:\n",
    "            self.simFields += [\"velocityZ\"]\n",
    "        if \"dens\" in simFields:\n",
    "            self.simFields += [\"density\"]\n",
    "        if \"pres\" in simFields:\n",
    "            self.simFields += [\"pressure\"]\n",
    "\n",
    "        self.simParams = simParams\n",
    "        self.printLevel = printLevel\n",
    "        self.logLevel = logLevel\n",
    "\n",
    "        self.summaryPrint = []\n",
    "        self.summaryLog = []\n",
    "        self.summaryPrint += [\"Dataset \" + name + \" at \" + str(dataDirs)]\n",
    "        self.summaryLog   += [\"Dataset \" + name + \" at \" + str(dataDirs)]\n",
    "        self.summaryPrint += [self.getFilterInfoString()]\n",
    "        self.summaryLog   += [self.getFilterInfoString()]\n",
    "\n",
    "        # BUILD FULL FILE LIST\n",
    "        self.dataPaths = []\n",
    "        self.dataPathModes = []\n",
    "\n",
    "        for dataDir in dataDirs:\n",
    "            topDirs = os.listdir(dataDir)\n",
    "            topDirs.sort()\n",
    "\n",
    "            # top level folders\n",
    "            for topDir in topDirs:\n",
    "                if filterTop:\n",
    "                    # continue when excluding or including according to filter\n",
    "                    if excludeFilterTop == any( item in topDir for item in filterTop ):\n",
    "                        continue\n",
    "\n",
    "                match = -1\n",
    "                # compute matching top filter for according sim or frame filtering\n",
    "                if len(filterSim) > 1 or len(filterFrame) > 1:\n",
    "                    for i in range(len(filterTop)):\n",
    "                        if filterTop[i] in topDir:\n",
    "                            match = i\n",
    "                            break\n",
    "                    assert (match >= 0), \"Match computation error\"\n",
    "\n",
    "                simDir = os.path.join(dataDir, topDir)\n",
    "                sims = os.listdir(simDir)\n",
    "                sims.sort()\n",
    "\n",
    "                if printLevel == \"top\":\n",
    "                    self.summaryPrint += [\"Top folder loaded: \" + simDir.replace(dataDir + \"/\", \"\")]\n",
    "                if logLevel == \"top\":\n",
    "                    self.summaryLog   += [\"Top folder loaded: \" + simDir.replace(dataDir + \"/\", \"\")]\n",
    "\n",
    "                # sim_000001 folders\n",
    "                for sim in sims:\n",
    "                    currentDir = os.path.join(simDir, sim)\n",
    "                    if not os.path.isdir(currentDir):\n",
    "                        continue\n",
    "\n",
    "                    if len(filterSim) > 0:\n",
    "                        simNum = int(sim.split(\"_\")[1])\n",
    "                        if len(filterSim) == 1:\n",
    "                            if type(filterSim[0]) is tuple:\n",
    "                                inside = simNum >= filterSim[0][0] and simNum < filterSim[0][1]\n",
    "                            elif type(filterSim[0]) is list:\n",
    "                                inside = simNum in filterSim[0]\n",
    "                        else:\n",
    "                            if type(filterSim[match]) is tuple:\n",
    "                                inside = simNum >= filterSim[match][0] and simNum < filterSim[match][1]\n",
    "                            elif type(filterSim[match]) is list:\n",
    "                                inside = simNum in filterSim[match]\n",
    "                        # continue when excluding or including according to filter\n",
    "                        if inside == excludefilterSim:\n",
    "                            continue\n",
    "\n",
    "                    if printLevel == \"sim\":\n",
    "                        self.summaryPrint += [\"Sim loaded: \" + currentDir.replace(dataDir + \"/\", \"\")]\n",
    "                    if logLevel == \"sim\":\n",
    "                        self.summaryLog   += [\"Sim loaded: \" + currentDir.replace(dataDir + \"/\", \"\")]\n",
    "\n",
    "                    # individual simulation frames\n",
    "                    minFrame = filterFrame[0][0] if len(filterFrame) == 1 else filterFrame[match][0]\n",
    "                    maxFrame = filterFrame[0][1] if len(filterFrame) == 1 else filterFrame[match][1]\n",
    "                    seqLength = sequenceLength[0][0] if len(sequenceLength) == 1 else sequenceLength[match][0]\n",
    "                    seqSkip   = sequenceLength[0][1] if len(sequenceLength) == 1 else sequenceLength[match][1]\n",
    "                    for seqStart in range(minFrame, maxFrame, seqLength*seqSkip):\n",
    "                        validSeq = True\n",
    "                        for frame in range(seqStart, seqStart+seqLength*seqSkip, seqSkip):\n",
    "                            # discard incomplete sequences at simulation end\n",
    "                            if seqStart+seqLength*seqSkip > maxFrame:\n",
    "                                validSeq = False\n",
    "                                break\n",
    "\n",
    "                            for field in self.simFields:\n",
    "                                currentField = os.path.join(currentDir, \"%s_%06d.npz\" % (field, frame))\n",
    "                                if not os.path.isfile(currentField):\n",
    "                                    raise FileNotFoundError(\"Could not load %s file: %s\" % (field, currentField))\n",
    "\n",
    "                        # imcomplete sequence means there are no more frames left\n",
    "                        if not validSeq:\n",
    "                            break\n",
    "\n",
    "                        if printLevel == \"full\":\n",
    "                            self.summaryPrint += [\"Frames %s loaded: %s/%s_%06d-%06d(%03d).npz\" % (\"-\".join(self.simFields),\n",
    "                                        currentDir.replace(dataDir + \"/\", \"\"), \"-\".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]\n",
    "                        if logLevel == \"full\":\n",
    "                            self.summaryLog   += [\"Frames %s loaded: %s/%s_%06d-%06d(%03d).npz\" % (\"-\".join(self.simFields),\n",
    "                                        currentDir.replace(dataDir + \"/\", \"\"), \"-\".join(self.simFields), seqStart, seqStart + seqLength*(seqSkip-1), seqSkip)]\n",
    "\n",
    "                        self.dataPaths.append((currentDir, seqStart, seqStart + seqLength*seqSkip, seqSkip))\n",
    "\n",
    "        self.summaryPrint += [\"Dataset Length: %d\\n\" % len(self.dataPaths)]\n",
    "        self.summaryLog   += [\"Dataset Length: %d\\n\" % len(self.dataPaths)]\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataPaths)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx:int) -> dict:\n",
    "        # sequence indexing\n",
    "        basePath, seqStart, seqEnd, seqSkip = self.dataPaths[idx]\n",
    "        seqLen = int((seqEnd - seqStart) / seqSkip)\n",
    "        if self.randSeqOffset:\n",
    "            halfSeq = int((seqEnd-seqStart) / 2)\n",
    "            offset = torch.randint(-halfSeq, halfSeq+1, (1,)).item()\n",
    "            if seqStart + offset >= self.filterFrame[0][0] and seqEnd + offset < self.filterFrame[0][1]:\n",
    "                seqStart = seqStart + offset\n",
    "                seqEnd = seqEnd + offset\n",
    "\n",
    "        # loading simulation parameters\n",
    "        with open(os.path.join(basePath, \"src\", \"description.json\")) as f:\n",
    "            loadedJSON = json.load(f)\n",
    "\n",
    "            loadNames = [\"Reynolds Number\", \"Mach Number\", \"Drag Coefficient\", \"Lift Coefficient\", \"Z Slice\"]\n",
    "            loadedParams = {}\n",
    "            for loadName in loadNames:\n",
    "                loadedParam = np.zeros(seqLen, dtype=np.float32)\n",
    "                if loadName in loadedJSON:\n",
    "                    temp = loadedJSON[loadName]\n",
    "                    if isinstance(temp, int) or isinstance(temp, float):\n",
    "                        temp = np.array(temp, dtype=np.float32)\n",
    "                        loadedParam[0:] = np.repeat(temp, seqLen)\n",
    "                    elif isinstance(temp, list):\n",
    "                        loadedParam[0:] = temp[seqStart:seqEnd:seqSkip]\n",
    "                    else:\n",
    "                        raise ValueError(\"Invalid simulation parameter data type\")\n",
    "                loadedParams[loadName] = loadedParam\n",
    "\n",
    "            if \"rey\" in self.simParams and \"mach\" in self.simParams:\n",
    "                simParameters = np.stack([loadedParams[\"Reynolds Number\"], loadedParams[\"Mach Number\"]], axis=1)\n",
    "            elif \"rey\" in self.simParams:\n",
    "                simParameters = np.reshape(loadedParams[\"Reynolds Number\"], (-1,1))\n",
    "            elif \"mach\" in self.simParams:\n",
    "                simParameters = np.reshape(loadedParams[\"Mach Number\"], (-1,1))\n",
    "            elif \"zslice\" in self.simParams:\n",
    "                simParameters = np.reshape(loadedParams[\"Z Slice\"], (-1,1))\n",
    "            elif not self.simParams:\n",
    "                simParameters ={}\n",
    "            else:\n",
    "                raise ValueError(\"Invalid specification of simulation parameters\")\n",
    "\n",
    "        # loading obstacle mask\n",
    "        if os.path.isfile(os.path.join(basePath, \"obstacle_mask.npz\")):\n",
    "            obsMask = np.load(os.path.join(basePath, \"obstacle_mask.npz\"))['arr_0']\n",
    "        else:\n",
    "            obsMask = None\n",
    "\n",
    "        # loading fields and combining them with simulation parameters\n",
    "        loaded = {}\n",
    "        for field in self.simFields:\n",
    "            loaded[field] = []\n",
    "\n",
    "        for frame in range(seqStart, seqEnd, seqSkip):\n",
    "            for field in self.simFields:\n",
    "                loadedArr = np.load(os.path.join(basePath, \"%s_%06d.npz\" % (field,frame)))['arr_0']\n",
    "                loaded[field] += [loadedArr.astype(np.float32)]\n",
    "\n",
    "        loadedFields = []\n",
    "        for field in self.simFields:\n",
    "            loadedFields += [np.stack(loaded[field], axis=0)]\n",
    "\n",
    "        if type(simParameters) is not dict:\n",
    "            vel = loadedFields[0]\n",
    "            if vel.ndim == 4:\n",
    "                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis]\n",
    "                simParExpanded = np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3)\n",
    "            elif vel.ndim == 5:\n",
    "                simParExpanded = simParameters[:,:,np.newaxis,np.newaxis,np.newaxis]\n",
    "                simParExpanded = np.repeat(np.repeat(np.repeat(simParExpanded, vel.shape[2], axis=2), vel.shape[3], axis=3), vel.shape[4], axis=4)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid input shape when loading samples!\")\n",
    "            loadedFields += [simParExpanded]\n",
    "\n",
    "        data = np.concatenate(loadedFields, axis=1) # ORDER (fields): velocity (x,y), velocity z / density, pressure, ORDER (params): rey, mach, zslice\n",
    "\n",
    "        # output\n",
    "        dataPath = \"%s/%s_%06d-%06d(%03d).npz\" % (basePath, \"-\".join(self.simFields), seqStart, seqEnd - seqSkip, seqSkip)\n",
    "        sample = {\"data\" : data, \"simParameters\" : simParameters, \"allParameters\" : loadedParams, \"path\" : dataPath}\n",
    "        if obsMask is not None:\n",
    "            sample[\"obsMask\"] = obsMask\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        else:\n",
    "            print(\"WARNING: no data transformations are employed!\")\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "    def printDatasetInfo(self):\n",
    "        if self.transform:\n",
    "            s  = \"%s - Data Augmentations: %s\\n\" % (self.name, len(self.transform.p_d.augmentations))\n",
    "            s += \"\\tactivate augmentations: [%s]\\n\" % \", \".join(self.transform.p_d.augmentations)\n",
    "            if self.transform.crop:\n",
    "                s += \"\\tcrop settings: outputSize (%d, %d)\\n\" % (self.transform.outputSize[0], self.transform.outputSize[1])\n",
    "            if self.transform.resize:\n",
    "                s += \"\\tresize settings: outputSize (%d, %d)\\n\" % (self.transform.outputSize[0], self.transform.outputSize[1])\n",
    "\n",
    "            self.summaryPrint += [s]\n",
    "            self.summaryLog   += [s]\n",
    "\n",
    "        print('\\n'.join(self.summaryPrint))\n",
    "        logging.info('\\n'.join(self.summaryLog))\n",
    "\n",
    "    def getFilterInfoString(self) -> str:\n",
    "        s  = \"%s - Data Filter Setup: \\n\" % (self.name)\n",
    "        s += \"\\tdataDirs: %s\\n\" % (str(self.dataDirs))\n",
    "        s += \"\\tfilterTop: %s  exlude: %s\\n\" % (str(self.filterTop), self.excludeFilterTop)\n",
    "        s += \"\\tfilterSim: %s  exlude: %s\\n\" % (str(self.filterSim), self.excludefilterSim)\n",
    "        s += \"\\tfilterFrame: %s\\n\" % (str(self.filterFrame))\n",
    "        s += \"\\tsequenceLength: %s\\n\" % (str(self.sequenceLength))\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T13:15:59.458066Z",
     "iopub.status.busy": "2026-01-20T13:15:59.457449Z",
     "iopub.status.idle": "2026-01-20T13:16:33.298306Z",
     "shell.execute_reply": "2026-01-20T13:16:33.297083Z",
     "shell.execute_reply.started": "2026-01-20T13:15:59.458027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/home/nkhaous/myLLF/JiT_SysId/data/128_inc\"\n",
    "p_d = DataParams(batch=64, augmentations=[\"normalize\"], sequenceLength=[10,2], randSeqOffset=True,\n",
    "            dataSize=[128,64], dimension=2, simFields=[\"pres\"], simParams=[\"rey\"], normalizeMode=\"incMixed\")\n",
    "\n",
    "trainSet = TurbulenceDataset(\"Training\", [data_path], filterTop=[\"128_inc\"], filterSim=[(10,81)], filterFrame=[(800,1300)],\n",
    "                sequenceLength=[p_d.sequenceLength], randSeqOffset=p_d.randSeqOffset, simFields=p_d.simFields, simParams=p_d.simParams, printLevel=\"sim\")\n",
    "\n",
    "transTrain = Transforms(p_d)\n",
    "trainSet.transform = transTrain\n",
    "# trainSet.printDatasetInfo()\n",
    "\n",
    "trainSampler = RandomSampler(trainSet)\n",
    "#trainSampler = SubsetRandomSampler(range(2))\n",
    "trainLoader = DataLoader(trainSet, sampler=trainSampler,\n",
    "                batch_size=p_d.batch, drop_last=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'simParameters', 'allParameters', 'path', 'obsMask'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(trainLoader)).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T15:39:55.822105Z",
     "iopub.status.busy": "2026-01-20T15:39:55.821708Z",
     "iopub.status.idle": "2026-01-20T15:40:14.705639Z",
     "shell.execute_reply": "2026-01-20T15:40:14.704652Z",
     "shell.execute_reply.started": "2026-01-20T15:39:55.822073Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 4, 128, 64])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(trainLoader))['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T15:40:30.574694Z",
     "iopub.status.busy": "2026-01-20T15:40:30.574390Z",
     "iopub.status.idle": "2026-01-20T15:40:34.328525Z",
     "shell.execute_reply": "2026-01-20T15:40:34.327730Z",
     "shell.execute_reply.started": "2026-01-20T15:40:30.574661Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "testSets = {\n",
    "    \"lowRey\":\n",
    "        TurbulenceDataset(\"Test Low Reynolds 100-200\", [data_path], filterTop=[\"128_inc\"], filterSim=[[82,84,86,88,90]],\n",
    "                filterFrame=[(1000,1150)], sequenceLength=[[60,2]], simFields=p_d.simFields, simParams=p_d.simParams, printLevel=\"sim\"),\n",
    "    \"highRey\" :\n",
    "        TurbulenceDataset(\"Test High Reynolds 900-1000\", [data_path], filterTop=[\"128_inc\"], filterSim=[[0,2,4,6,8]],\n",
    "                filterFrame=[(1000,1150)], sequenceLength=[[60,2]], simFields=p_d.simFields, simParams=p_d.simParams, printLevel=\"sim\"),\n",
    "    \"varReyIn\" :\n",
    "        TurbulenceDataset(\"Test Varying Reynolds Number (200-900)\", [data_path], filterTop=[\"128_reyVar\"], filterSim=[[0]],\n",
    "                filterFrame=[(300,800)], sequenceLength=[[250,2]], simFields=p_d.simFields, simParams=p_d.simParams, printLevel=\"sim\"),\n",
    "}\n",
    "\n",
    "\n",
    "test_loaders = []\n",
    "for shortName, testSet in testSets.items():\n",
    "    p_d_test = copy.deepcopy(p_d)\n",
    "    p_d_test.augmentations = [\"normalize\"]\n",
    "    p_d_test.sequenceLength = testSet.sequenceLength\n",
    "    p_d_test.randSeqOffset = False\n",
    "    if p_d.sequenceLength[0] != p_d_test.sequenceLength[0]:\n",
    "        p_d_test.batch = 1\n",
    "\n",
    "    transTest = Transforms(p_d_test)\n",
    "    testSet.transform = transTest\n",
    "    # testSet.printDatasetInfo()\n",
    "    testSampler = SequentialSampler(testSet)\n",
    "    #testSampler = SubsetRandomSampler(range(2))\n",
    "    testLoader = DataLoader(testSet, sampler=testSampler,\n",
    "                    batch_size=p_d_test.batch, drop_last=False, num_workers=4)\n",
    "    test_loaders.append(testLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T16:02:30.418697Z",
     "iopub.status.busy": "2026-01-20T16:02:30.418391Z",
     "iopub.status.idle": "2026-01-20T16:02:30.483075Z",
     "shell.execute_reply": "2026-01-20T16:02:30.481971Z",
     "shell.execute_reply.started": "2026-01-20T16:02:30.418671Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_2d_sincos_pos_embed(embed_dim, grid_size_h, grid_size_w):\n",
    "    \"\"\"\n",
    "    Generate 2D sin-cos positional embedding pour une grille rectangulaire.\n",
    "    grid_size_h: nombre de patchs en hauteur (ex: 128/16 = 8)\n",
    "    grid_size_w: nombre de patchs en largeur (ex: 64/16 = 4)\n",
    "    \"\"\"\n",
    "    # Création des axes avec leurs tailles respectives\n",
    "    grid_h = np.arange(grid_size_h, dtype=np.float32)\n",
    "    grid_w = np.arange(grid_size_w, dtype=np.float32)\n",
    "    \n",
    "    # Génération de la grille (meshgrid)\n",
    "    grid = np.meshgrid(grid_w, grid_h) # Attention à l'ordre (w, h)\n",
    "    grid = np.stack(grid, axis=0)\n",
    "    \n",
    "    # On reformate pour l'envoyer à la fonction suivante\n",
    "    grid = grid.reshape([2, 1, grid_size_h, grid_size_w])\n",
    "    \n",
    "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
    "    return pos_embed\n",
    "\n",
    "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
    "    assert embed_dim % 2 == 0\n",
    "    \n",
    "    # grid[0] est l'axe horizontal (w), grid[1] est l'axe vertical (h)\n",
    "    # On utilise la moitié des dimensions pour chaque axe\n",
    "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1]) # (H*W, D/2)\n",
    "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0]) # (H*W, D/2)\n",
    "    \n",
    "    # On concatène pour avoir le vecteur complet (H*W, D)\n",
    "    emb = np.concatenate([emb_h, emb_w], axis=1)\n",
    "    return emb\n",
    "\n",
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    assert embed_dim % 2 == 0\n",
    "    omega = np.arange(embed_dim // 2, dtype=np.float32)\n",
    "    omega /= embed_dim / 2.\n",
    "    omega = 1. / 10000**omega\n",
    "    pos = pos.reshape(-1)\n",
    "    out = np.einsum('m,d->md', pos, omega)\n",
    "    emb_sin = np.sin(out)\n",
    "    emb_cos = np.cos(out)\n",
    "    emb = np.concatenate([emb_sin, emb_cos], axis=1)\n",
    "    return emb\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        norm = torch.sqrt(torch.mean(x ** 2, dim=-1, keepdim=True) + self.eps)\n",
    "        return x / norm * self.weight\n",
    "\n",
    "def modulate(x, shift, scale):\n",
    "    return x * (1 + scale.unsqueeze(1)) + shift.unsqueeze(1)\n",
    "\n",
    "\n",
    "class BottleneckPatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=(128, 64), patch_size=16, in_chans=1, pca_dim=128, embed_dim=384, bias=True):\n",
    "        super().__init__()\n",
    "        # On s'assure que img_size est un tuple (Hauteur, Largeur)\n",
    "        self.img_size = img_size \n",
    "        self.patch_size = (patch_size, patch_size)\n",
    "        \n",
    "        # Calcul de la grille de patchs pour un format rectangulaire\n",
    "        # Pour 128x64 et patch=16 -> grid_size = (8, 4)\n",
    "        self.grid_size = (img_size[0] // patch_size, img_size[1] // patch_size)\n",
    "        self.num_patches = self.grid_size[0] * self.grid_size[1]\n",
    "        \n",
    "        # La projection reste identique dans son principe :\n",
    "        # Elle transforme chaque patch de pixels en un vecteur de dimension pca_dim\n",
    "        self.proj1 = nn.Conv2d(in_chans, pca_dim, kernel_size=patch_size, stride=patch_size, bias=False)\n",
    "        \n",
    "        # Elle projette ensuite ce vecteur vers la dimension du Transformer (embed_dim)\n",
    "        self.proj2 = nn.Conv2d(pca_dim, embed_dim, kernel_size=1, stride=1, bias=bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape attendu : [Batch, Channels, H, W]\n",
    "        B, C, H, W = x.shape\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"La taille de l'image en entrée ({H}x{W}) ne correspond pas à la taille configurée ({self.img_size[0]}x{self.img_size[1]})\"\n",
    "        \n",
    "        # 1. Convolution : extrait les patchs et les projette\n",
    "        # [B, in_chans, 128, 64] -> [B, embed_dim, 8, 4]\n",
    "        x = self.proj1(x)\n",
    "        x = self.proj2(x)\n",
    "        \n",
    "        # 2. Flatten : on aplatit la grille spatiale en une séquence\n",
    "        # [B, embed_dim, 8, 4] -> [B, embed_dim, 32]\n",
    "        x = x.flatten(2)\n",
    "        \n",
    "        # 3. Transpose : on met la dimension d'embedding à la fin (standard Transformer)\n",
    "        # [B, embed_dim, 32] -> [B, 32, embed_dim]\n",
    "        x = x.transpose(1, 2)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class TimestepEmbedder(nn.Module):\n",
    "    def __init__(self, hidden_size, frequency_embedding_size=256):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(frequency_embedding_size, hidden_size, bias=True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, hidden_size, bias=True),\n",
    "        )\n",
    "        self.frequency_embedding_size = frequency_embedding_size\n",
    "    \n",
    "    @staticmethod\n",
    "    def timestep_embedding(t, dim, max_period=10000):\n",
    "        half = dim // 2\n",
    "        freqs = torch.exp(\n",
    "            -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32, device=t.device) / half\n",
    "        )\n",
    "        args = t[:, None].float() * freqs[None]\n",
    "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        if dim % 2:\n",
    "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "        return embedding\n",
    "    \n",
    "    def forward(self, t):\n",
    "        t_freq = self.timestep_embedding(t, self.frequency_embedding_size)\n",
    "        t_emb = self.mlp(t_freq)\n",
    "        return t_emb\n",
    "    \n",
    "\n",
    "class ControlEmbedder(nn.Module):\n",
    "    \"\"\"Embed control signals (u_past and u_curr) into hidden dimension\"\"\"\n",
    "    def __init__(self, past_window, hidden_size):\n",
    "        super().__init__()\n",
    "        # Embed past_window + 1 (past + current) control values\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(past_window + 1, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "        )\n",
    "    \n",
    "    def forward(self, u_past, u_curr):\n",
    "        # u_past: (B, past_window, 1), u_curr: (B, 1)\n",
    "        u_combined = torch.cat([u_past.squeeze(-1), u_curr], dim=1)  # (B, past_window + 1)\n",
    "        return self.mlp(u_combined)\n",
    "    \n",
    "    \n",
    "def scaled_dot_product_attention(query, key, value, dropout_p=0.0):\n",
    "    L, S = query.size(-2), key.size(-2)\n",
    "    scale_factor = 1 / math.sqrt(query.size(-1))\n",
    "    attn_bias = torch.zeros(query.size(0), 1, L, S, dtype=query.dtype, device=query.device)\n",
    "    \n",
    "    with torch.cuda.amp.autocast(enabled=False):\n",
    "        attn_weight = query.float() @ key.float().transpose(-2, -1) * scale_factor\n",
    "    attn_weight += attn_bias\n",
    "    attn_weight = torch.softmax(attn_weight, dim=-1)\n",
    "    attn_weight = torch.dropout(attn_weight, dropout_p, train=True)\n",
    "    return attn_weight @ value\n",
    "    \n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=True, qk_norm=True, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        \n",
    "        self.q_norm = RMSNorm(head_dim) if qk_norm else nn.Identity()\n",
    "        self.k_norm = RMSNorm(head_dim) if qk_norm else nn.Identity()\n",
    "        \n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        \n",
    "        q = self.q_norm(q)\n",
    "        k = self.k_norm(k)\n",
    "        \n",
    "        x = scaled_dot_product_attention(q, k, v, dropout_p=self.attn_drop.p if self.training else 0.)\n",
    "        \n",
    "        x = x.transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "class SwiGLUFFN(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, drop=0.0, bias=True):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(hidden_dim * 2 / 3)\n",
    "        self.w12 = nn.Linear(dim, 2 * hidden_dim, bias=bias)\n",
    "        self.w3 = nn.Linear(hidden_dim, dim, bias=bias)\n",
    "        self.ffn_dropout = nn.Dropout(drop)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x12 = self.w12(x)\n",
    "        x1, x2 = x12.chunk(2, dim=-1)\n",
    "        hidden = F.silu(x1) * x2\n",
    "        return self.w3(self.ffn_dropout(hidden))\n",
    "    \n",
    "\n",
    "class FinalLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, patch_size, out_channels):\n",
    "        super().__init__()\n",
    "        self.norm_final = RMSNorm(hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, patch_size * patch_size * out_channels, bias=True)\n",
    "        self.adaLN_modulation = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, 2 * hidden_size, bias=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, c):\n",
    "        shift, scale = self.adaLN_modulation(c).chunk(2, dim=1)\n",
    "        x = modulate(self.norm_final(x), shift, scale)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class JiTBlock(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads, mlp_ratio=4.0, attn_drop=0.0, proj_drop=0.0):\n",
    "        super().__init__()\n",
    "        self.norm1 = RMSNorm(hidden_size, eps=1e-6)\n",
    "        self.attn = Attention(hidden_size, num_heads=num_heads, qkv_bias=True, qk_norm=True,\n",
    "                              attn_drop=attn_drop, proj_drop=proj_drop)\n",
    "        self.norm2 = RMSNorm(hidden_size, eps=1e-6)\n",
    "        mlp_hidden_dim = int(hidden_size * mlp_ratio)\n",
    "        self.mlp = SwiGLUFFN(hidden_size, mlp_hidden_dim, drop=proj_drop)\n",
    "        self.adaLN_modulation = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, 6 * hidden_size, bias=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, c):\n",
    "        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = self.adaLN_modulation(c).chunk(6, dim=-1)\n",
    "        x = x + gate_msa.unsqueeze(1) * self.attn(modulate(self.norm1(x), shift_msa, scale_msa))\n",
    "        x = x + gate_mlp.unsqueeze(1) * self.mlp(modulate(self.norm2(x), shift_mlp, scale_mlp))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class JitFluid(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_size=(128, 64),\n",
    "        patch_size=16,\n",
    "        in_channels=4,        # CHANGÉ : 4 canaux en entrée (VelX, VelY, Pres, Rey)\n",
    "        out_channels=3,       # CHANGÉ : 3 canaux en sortie (On ne prédit que la physique)\n",
    "        past_window=9,\n",
    "        hidden_size=384,\n",
    "        depth=12,\n",
    "        num_heads=6,\n",
    "        mlp_ratio=4.0,\n",
    "        bottleneck_dim=64,\n",
    "        diffusion_steps=50,\n",
    "        P_mean=-0.8,\n",
    "        P_std=0.8,\n",
    "        t_eps=0.05,\n",
    "        noise_scale=1.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.in_channels = in_channels   # 4\n",
    "        self.out_channels = out_channels # 3\n",
    "        self.hidden_size = hidden_size\n",
    "        self.past_window = past_window\n",
    "        self.timesteps = diffusion_steps\n",
    "        self.P_mean = P_mean\n",
    "        self.P_std = P_std\n",
    "        self.t_eps = t_eps\n",
    "        self.noise_scale = noise_scale\n",
    "        \n",
    "        # 1. Embedders\n",
    "        self.t_embedder = TimestepEmbedder(hidden_size)\n",
    "        # On garde le ControlEmbedder pour la valeur scalaire du Reynolds\n",
    "        self.control_embedder = ControlEmbedder(past_window, hidden_size)\n",
    "        \n",
    "        # 2. Patch embedding pour la target frame bruitée (3 canaux physiques)\n",
    "        # Note : On ne bruite que la physique, pas le Reynolds\n",
    "        self.x_embedder = BottleneckPatchEmbed(\n",
    "            img_size, patch_size, out_channels, bottleneck_dim, hidden_size, bias=True\n",
    "        )\n",
    "        \n",
    "        # 3. Patch embedding pour le passé (4 canaux par frame)\n",
    "        # 9 frames * 4 canaux = 36 canaux en entrée\n",
    "        self.cond_embedder = BottleneckPatchEmbed(\n",
    "            img_size, patch_size, past_window * in_channels, bottleneck_dim, hidden_size, bias=True\n",
    "        )\n",
    "        \n",
    "        # Positional embedding (Grille 8x4)\n",
    "        num_patches = self.x_embedder.num_patches\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, hidden_size), requires_grad=False)\n",
    "        \n",
    "        # Transformer blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            JiTBlock(hidden_size, num_heads, mlp_ratio=mlp_ratio)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        \n",
    "        # Final layer (Sortie vers 3 canaux physiques)\n",
    "        self.final_layer = FinalLayer(hidden_size, patch_size, self.out_channels)\n",
    "        \n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        def _basic_init(module):\n",
    "            if isinstance(module, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "        self.apply(_basic_init)\n",
    "        \n",
    "        # Calcul de la grille rectangulaire pour l'embedding de position\n",
    "        grid_h = self.img_size[0] // self.patch_size # 128 / 16 = 8\n",
    "        grid_w = self.img_size[1] // self.patch_size # 64 / 16 = 4\n",
    "        \n",
    "        # Appel de la fonction rectangulaire\n",
    "        pos_embed = get_2d_sincos_pos_embed(\n",
    "            self.pos_embed.shape[-1], \n",
    "            grid_h, \n",
    "            grid_w\n",
    "        )\n",
    "        self.pos_embed.data.copy_(torch.from_numpy(pos_embed).float().unsqueeze(0))\n",
    "        \n",
    "        # Initialisation des patch embeddings\n",
    "        for embedder in [self.x_embedder, self.cond_embedder]:\n",
    "            w1 = embedder.proj1.weight.data\n",
    "            nn.init.xavier_uniform_(w1.view([w1.shape[0], -1]))\n",
    "            w2 = embedder.proj2.weight.data\n",
    "            nn.init.xavier_uniform_(w2.view([w2.shape[0], -1]))\n",
    "            nn.init.constant_(embedder.proj2.bias, 0)\n",
    "        \n",
    "        # Zero-out adaLN et output (pour démarrer comme une fonction identité/neutre)\n",
    "        for block in self.blocks:\n",
    "            nn.init.constant_(block.adaLN_modulation[-1].weight, 0)\n",
    "            nn.init.constant_(block.adaLN_modulation[-1].bias, 0)\n",
    "        \n",
    "        nn.init.constant_(self.final_layer.adaLN_modulation[-1].weight, 0)\n",
    "        nn.init.constant_(self.final_layer.adaLN_modulation[-1].bias, 0)\n",
    "        nn.init.constant_(self.final_layer.linear.weight, 0)\n",
    "        nn.init.constant_(self.final_layer.linear.bias, 0)\n",
    "    \n",
    "    def unpatchify(self, x):\n",
    "        \"\"\"\n",
    "        x: (N, num_patches, patch_size**2 * C) -> imgs: (N, C, H, W)\n",
    "        N = Batch size\n",
    "        num_patches = 32 (grille 8x4)\n",
    "        C = out_channels (3 : VelX, VelY, Pres)\n",
    "        \"\"\"\n",
    "        p = self.patch_size\n",
    "        c = self.out_channels\n",
    "        \n",
    "        # CHANGÉ : On ne fait plus de racine carrée. \n",
    "        # On calcule h et w à partir de la taille de l'image et du patch.\n",
    "        h = self.img_size[0] // p  # 128 // 16 = 8 patchs en hauteur\n",
    "        w = self.img_size[1] // p  # 64 // 16 = 4 patchs en largeur\n",
    "        \n",
    "        # Vérification de sécurité pour s'assurer que le nombre de tokens \n",
    "        # correspond bien à notre grille 8x4\n",
    "        assert h * w == x.shape[1], f\"Le nombre de patchs ({x.shape[1]}) ne correspond pas à la grille {h}x{w}\"\n",
    "\n",
    "        # 1. Reshape : On sépare les pixels de chaque patch et on recrée la grille spatiale\n",
    "        # [N, 32, 768] -> [N, 8, 4, 16, 16, 3]\n",
    "        x = x.reshape(shape=(x.shape[0], h, w, p, p, c))\n",
    "        \n",
    "        # 2. Permutation (Einsum) : C'est l'étape magique.\n",
    "        # On déplace les dimensions pour que les canaux (c) soient en premier (N, C, ...)\n",
    "        # et que les pixels des patchs (p, q) soient placés à côté de leurs indices de grille (h, w).\n",
    "        # 'nhwpqc' -> 'nchpwq'\n",
    "        # n: batch, h: grille_H, w: grille_W, p: patch_H, q: patch_W, c: channels\n",
    "        x = torch.einsum('nhwpqc->nchpwq', x)\n",
    "        \n",
    "        # 3. Final Reshape : On fusionne la grille et les pixels des patchs pour recréer l'image complète.\n",
    "        # [N, 3, 8, 16, 4, 16] -> [N, 3, 128, 64]\n",
    "        imgs = x.reshape(shape=(x.shape[0], c, h * p, w * p))\n",
    "        \n",
    "        return imgs\n",
    "    \n",
    "    def sample_t(self, n, device):\n",
    "        \"\"\"Sample timesteps from logit-normal distribution\"\"\"\n",
    "        z = torch.randn(n, device=device) * self.P_std + self.P_mean\n",
    "        return torch.sigmoid(z)\n",
    "    \n",
    "    def forward(self, cond_frames, cond_u_past, cond_u_curr, target_frame):\n",
    "        B = target_frame.size(0)\n",
    "        device = target_frame.device\n",
    "        \n",
    "        # 1. Échantillonnage du temps et ajout de bruit (Diffusion)\n",
    "        t = self.sample_t(B, device).view(-1, *([1] * (target_frame.ndim - 1)))\n",
    "        t_flat = t.flatten()\n",
    "        \n",
    "        e = torch.randn_like(target_frame) * self.noise_scale\n",
    "        z_t = t * target_frame + (1 - t) * e\n",
    "        \n",
    "        # Vélocité cible pour la v-loss (plus stable pour les fluides)\n",
    "        v = (target_frame - z_t) / (1 - t).clamp_min(self.t_eps)\n",
    "        \n",
    "        # 2. Embedding du conditionnement passé (4 canaux)\n",
    "        # CHANGÉ : On passe de [B, 9, 4, 128, 64] à [B, 36, 128, 64]\n",
    "        cond_frames_reshaped = cond_frames.flatten(1, 2) \n",
    "        cond_tokens = self.cond_embedder(cond_frames_reshaped) \n",
    "        \n",
    "        # 3. Embedding de la cible bruitée (3 canaux)\n",
    "        x_tokens = self.x_embedder(z_t) \n",
    "        \n",
    "        # Fusion tokens + positions\n",
    "        tokens = x_tokens + cond_tokens + self.pos_embed\n",
    "        \n",
    "        # 4. Temps et contrôle (Reynolds)\n",
    "        t_emb = self.t_embedder(t_flat)\n",
    "        control_emb = self.control_embedder(cond_u_past, cond_u_curr)\n",
    "        c = t_emb + control_emb\n",
    "        \n",
    "        # 5. Transformer Blocks\n",
    "        for block in self.blocks:\n",
    "            tokens = block(tokens, c)\n",
    "        \n",
    "        # 6. Sortie et Reconstruction\n",
    "        x_pred_tokens = self.final_layer(tokens, c)\n",
    "        x_pred = self.unpatchify(x_pred_tokens)\n",
    "        \n",
    "        # Calcul de la v-pred pour la loss\n",
    "        v_pred = (x_pred - z_t) / (1 - t).clamp_min(self.t_eps)\n",
    "        loss = F.smooth_l1_loss(v_pred, v)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(self, cond_frames, cond_u_past, cond_u_curr, num_steps=50, method='heun'):\n",
    "        B = cond_frames.size(0)\n",
    "        device = cond_frames.device\n",
    "        H, W = self.img_size # (128, 64)\n",
    "        \n",
    "        # CHANGÉ : On commence avec un bruit à 3 canaux (Physique)\n",
    "        z = self.noise_scale * torch.randn(B, 3, H, W, device=device)\n",
    "        \n",
    "        timesteps = torch.linspace(0.0, 1.0, num_steps + 1, device=device)\n",
    "        \n",
    "        # Pré-calcul de l'embedding du passé (fixe pendant le sampling d'une frame)\n",
    "        cond_frames_reshaped = cond_frames.flatten(1, 2)\n",
    "        cond_tokens = self.cond_embedder(cond_frames_reshaped)\n",
    "        cond_tokens = cond_tokens + self.pos_embed\n",
    "        \n",
    "        control_emb = self.control_embedder(cond_u_past, cond_u_curr)\n",
    "        \n",
    "        for i in range(num_steps):\n",
    "            t_curr = timesteps[i]\n",
    "            t_next = timesteps[i + 1]\n",
    "            \n",
    "            if method == 'euler':\n",
    "                z = self._euler_step(z, t_curr, t_next, cond_tokens, control_emb)\n",
    "            elif method == 'heun':\n",
    "                z = self._heun_step(z, t_curr, t_next, cond_tokens, control_emb)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def _forward_sample(self, z, t, cond_tokens, control_emb):\n",
    "        B = z.size(0)\n",
    "        t_scalar = t.expand(B)\n",
    "        \n",
    "        # On embed l'échantillon bruité actuel\n",
    "        x_tokens = self.x_embedder(z)\n",
    "        tokens = x_tokens + cond_tokens # cond_tokens inclut déjà pos_embed\n",
    "        \n",
    "        t_emb = self.t_embedder(t_scalar)\n",
    "        c = t_emb + control_emb\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            tokens = block(tokens, c)\n",
    "        \n",
    "        # Prédiction de x (la frame propre)\n",
    "        x_pred_tokens = self.final_layer(tokens, c)\n",
    "        x_pred = self.unpatchify(x_pred_tokens)\n",
    "        \n",
    "        # Conversion en vélocité pour le pas d'intégration\n",
    "        t_broadcast = t.view(-1, *([1] * (z.ndim - 1)))\n",
    "        v_pred = (x_pred - z) / (1.0 - t_broadcast).clamp_min(self.t_eps)\n",
    "        \n",
    "        return v_pred\n",
    "    \n",
    "    def _euler_step(self, z, t_curr, t_next, cond_tokens, control_emb):\n",
    "        v_pred = self._forward_sample(z, t_curr, cond_tokens, control_emb)\n",
    "        z_next = z + (t_next - t_curr) * v_pred\n",
    "        return z_next\n",
    "    \n",
    "    def _heun_step(self, z, t_curr, t_next, cond_tokens, control_emb):\n",
    "        # First Euler step\n",
    "        v_pred_curr = self._forward_sample(z, t_curr, cond_tokens, control_emb)\n",
    "        z_euler = z + (t_next - t_curr) * v_pred_curr\n",
    "        \n",
    "        # Second evaluation\n",
    "        v_pred_next = self._forward_sample(z_euler, t_next, cond_tokens, control_emb)\n",
    "        \n",
    "        # Heun average\n",
    "        v_pred = 0.5 * (v_pred_curr + v_pred_next)\n",
    "        z_next = z + (t_next - t_curr) * v_pred\n",
    "        return z_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T16:05:14.923819Z",
     "iopub.status.busy": "2026-01-20T16:05:14.923426Z",
     "iopub.status.idle": "2026-01-20T16:05:14.937439Z",
     "shell.execute_reply": "2026-01-20T16:05:14.936471Z",
     "shell.execute_reply.started": "2026-01-20T16:05:14.923788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_jit_diffusion(model, train_loader, val_loader, num_epochs, device, lr=1e-4):\n",
    "    # 1. Configuration de l'optimiseur (AdamW est standard pour les Transformers)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.95), weight_decay=0.01)\n",
    "    \n",
    "    # 2. Scheduler : Décroissance cosinusoïdale (très efficace pour la diffusion)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        # Barre de progression\n",
    "        pbar = tqdm(train_loader, desc=f\"Époque {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        for batch in pbar:\n",
    "            # Extraction des données du dictionnaire TurbulenceDataset\n",
    "            # data shape: [64, 10, 4, 128, 64]\n",
    "            # params shape: [64, 10, 1]\n",
    "            data = batch['data'].to(device)\n",
    "            params = batch['simParameters'].to(device)\n",
    "\n",
    "            # --- DÉCOUPAGE PHYSIQUE ---\n",
    "            # Conditionnement : les 9 premières frames avec les 4 canaux (V, P, Re)\n",
    "            cond_frames = data[:, :9, :, :, :] \n",
    "            \n",
    "            # Cible : la 10ème frame, on ne prédit que les 3 canaux physiques (VelX, VelY, Pres)\n",
    "            target_frame = data[:, 9, :3, :, :]\n",
    "            \n",
    "            # --- DÉCOUPAGE DES PARAMÈTRES (Reynolds) ---\n",
    "            cond_u_past = params[:, :9, :]\n",
    "            cond_u_curr = params[:, 9, :]\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(cond_frames, cond_u_past, cond_u_curr, target_frame)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping (essentiel pour la stabilité des Transformers)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pbar.set_postfix({\"Loss\": f\"{loss.item():.6f}\"})\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        # 3. Validation (si un val_loader est fourni)\n",
    "        val_loss = 0.0\n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    data = batch['data'].to(device)\n",
    "                    params = batch['simParameters'].to(device)\n",
    "                    \n",
    "                    cond_frames = data[:, :9, :, :, :]\n",
    "                    target_frame = data[:, 9, :3, :, :]\n",
    "                    cond_u_past = params[:, :9, :]\n",
    "                    cond_u_curr = params[:, 9, :]\n",
    "                    \n",
    "                    loss = model(cond_frames, cond_u_past, cond_u_curr, target_frame)\n",
    "                    val_loss += loss.item()\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            print(f\"\\nÉpoque {epoch+1} terminée | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}\")\n",
    "            \n",
    "            # Sauvegarde du meilleur modèle\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), \"best_jit_fluid.pth\")\n",
    "                print(\"✓ Modèle sauvegardé !\")\n",
    "        else:\n",
    "            print(f\"\\nÉpoque {epoch+1} terminée | Train Loss: {avg_train_loss:.6f}\")\n",
    "\n",
    "    print(\"\\n✅ Entraînement terminé !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T16:06:24.021644Z",
     "iopub.status.busy": "2026-01-20T16:06:24.021220Z",
     "iopub.status.idle": "2026-01-20T16:06:24.559327Z",
     "shell.execute_reply": "2026-01-20T16:06:24.558412Z",
     "shell.execute_reply.started": "2026-01-20T16:06:24.021610Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle JitFluid initialisé sur cuda:0\n",
      "Nombre de paramètres : 33,615,744\n"
     ]
    }
   ],
   "source": [
    "# --- PARAMÈTRES DU MODÈLE ---\n",
    "# img_size: (Hauteur, Largeur) de tes simulations\n",
    "# patch_size: 16 donne une grille de 8x4 patchs\n",
    "# in_channels: 4 (VelX, VelY, Pres, Reynolds)\n",
    "# out_channels: 3 (On ne prédit que VelX, VelY, Pres)\n",
    "# past_window: 9 (On utilise les 9 premières frames pour prédire la 10ème)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Sélectionne le premier GPU\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "\n",
    "model = JitFluid(\n",
    "    img_size=(128, 64),\n",
    "    patch_size=16,\n",
    "    in_channels=4,\n",
    "    out_channels=3,\n",
    "    past_window=9,\n",
    "    hidden_size=384,\n",
    "    depth=12,\n",
    "    num_heads=6,\n",
    "    diffusion_steps=50\n",
    ").to(device)\n",
    "\n",
    "# --- VÉRIFICATION ---\n",
    "print(f\"Modèle JitFluid initialisé sur {device}\")\n",
    "print(f\"Nombre de paramètres : {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T16:06:53.177428Z",
     "iopub.status.busy": "2026-01-20T16:06:53.177080Z",
     "iopub.status.idle": "2026-01-20T16:10:39.488103Z",
     "shell.execute_reply": "2026-01-20T16:10:39.486710Z",
     "shell.execute_reply.started": "2026-01-20T16:06:53.177397Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 1/20:   0%|          | 0/27 [00:00<?, ?it/s]/tmp/ipykernel_608835/2149731546.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "Époque 1/20: 100%|██████████| 27/27 [00:07<00:00,  3.65it/s, Loss=0.046643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 1 terminée | Train Loss: 0.082989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 2/20: 100%|██████████| 27/27 [00:07<00:00,  3.67it/s, Loss=0.021637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 2 terminée | Train Loss: 0.034581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 3/20: 100%|██████████| 27/27 [00:07<00:00,  3.81it/s, Loss=0.009531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 3 terminée | Train Loss: 0.014956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 4/20: 100%|██████████| 27/27 [00:07<00:00,  3.76it/s, Loss=0.007716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 4 terminée | Train Loss: 0.009037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 5/20: 100%|██████████| 27/27 [00:07<00:00,  3.74it/s, Loss=0.006709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 5 terminée | Train Loss: 0.006890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 6/20: 100%|██████████| 27/27 [00:07<00:00,  3.69it/s, Loss=0.004607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 6 terminée | Train Loss: 0.005103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 7/20: 100%|██████████| 27/27 [00:07<00:00,  3.69it/s, Loss=0.003983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 7 terminée | Train Loss: 0.004309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 8/20: 100%|██████████| 27/27 [00:07<00:00,  3.62it/s, Loss=0.002761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 8 terminée | Train Loss: 0.003571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 9/20: 100%|██████████| 27/27 [00:07<00:00,  3.75it/s, Loss=0.002864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 9 terminée | Train Loss: 0.003020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 10/20: 100%|██████████| 27/27 [00:07<00:00,  3.78it/s, Loss=0.002437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 10 terminée | Train Loss: 0.002567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 11/20: 100%|██████████| 27/27 [00:07<00:00,  3.71it/s, Loss=0.002117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 11 terminée | Train Loss: 0.002221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 12/20: 100%|██████████| 27/27 [00:07<00:00,  3.81it/s, Loss=0.001981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 12 terminée | Train Loss: 0.002158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 13/20: 100%|██████████| 27/27 [00:07<00:00,  3.74it/s, Loss=0.001552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 13 terminée | Train Loss: 0.001861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 14/20: 100%|██████████| 27/27 [00:07<00:00,  3.65it/s, Loss=0.001558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 14 terminée | Train Loss: 0.001714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 15/20: 100%|██████████| 27/27 [00:07<00:00,  3.59it/s, Loss=0.001351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 15 terminée | Train Loss: 0.001516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 16/20: 100%|██████████| 27/27 [00:07<00:00,  3.68it/s, Loss=0.001706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 16 terminée | Train Loss: 0.001475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 17/20: 100%|██████████| 27/27 [00:07<00:00,  3.67it/s, Loss=0.001304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 17 terminée | Train Loss: 0.001355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 18/20: 100%|██████████| 27/27 [00:07<00:00,  3.61it/s, Loss=0.001241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 18 terminée | Train Loss: 0.001329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 19/20: 100%|██████████| 27/27 [00:07<00:00,  3.72it/s, Loss=0.001228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 19 terminée | Train Loss: 0.001325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Époque 20/20: 100%|██████████| 27/27 [00:07<00:00,  3.66it/s, Loss=0.001742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 20 terminée | Train Loss: 0.001245\n",
      "\n",
      "✅ Entraînement terminé !\n"
     ]
    }
   ],
   "source": [
    "train_jit_diffusion(model, trainLoader, None, num_epochs=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "# print model info and trainable weigths\n",
    "paramsTrainable = sum([np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters())])\n",
    "params = sum([np.prod(p.size()) for p in model.parameters()])\n",
    "#print(model)\n",
    "print(\"Trainable Weights (All Weights): %d (%d)\" % (paramsTrainable, params))\n",
    "\n",
    "# training loop\n",
    "print(\"\\nStarting training...\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    for s, sample in enumerate(trainLoader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        d = sample[\"data\"].to(device)\n",
    "\n",
    "        inputSteps = 2\n",
    "        cond = []\n",
    "        for i in range(inputSteps):\n",
    "            cond += [d[:,i:i+1]] # collect input steps\n",
    "        conditioning = torch.concat(cond, dim=2) # combine along channel dimension\n",
    "        data = d[:, inputSteps:inputSteps+1]\n",
    "\n",
    "        noise, predictedNoise = model(conditioning=conditioning, data=data)\n",
    "\n",
    "        loss = F.smooth_l1_loss(noise, predictedNoise)\n",
    "        print(\"    [Epoch %2d, Batch %4d]: %1.7f\" % (epoch, s, loss.detach().cpu().item()))\n",
    "        loss.backward()\n",
    "\n",
    "        losses += [loss.detach().cpu().item()]\n",
    "\n",
    "        optimizer.step()\n",
    "    print(\"[Epoch %2d, FULL]: %1.7f\" % (epoch, sum(losses)/len(losses)))\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T16:58:20.204023Z",
     "iopub.status.busy": "2026-01-20T16:58:20.203606Z",
     "iopub.status.idle": "2026-01-20T16:58:20.218002Z",
     "shell.execute_reply": "2026-01-20T16:58:20.217069Z",
     "shell.execute_reply.started": "2026-01-20T16:58:20.203983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_rollout(model, testLoader, device, num_steps_to_predict=None):\n",
    "    model.eval()\n",
    "    all_gt = []\n",
    "    all_pred = []\n",
    "    \n",
    "    past_window = model.past_window # Généralement 9\n",
    "\n",
    "    # Barre de progression principale (Séquences)\n",
    "    pbar_sequences = tqdm(testLoader, desc=\"Total Séquences\", unit=\"seq\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for s, batch in enumerate(pbar_sequences):\n",
    "            # data: [B, T, 4, 128, 64] | params: [B, T, 1]\n",
    "            data = batch['data'].to(device)\n",
    "            params = batch['simParameters'].to(device)\n",
    "            \n",
    "            B, T, C, H, W = data.shape\n",
    "            steps = T if num_steps_to_predict is None else num_steps_to_predict\n",
    "\n",
    "            # 1. Initialisation\n",
    "            prediction_phys = torch.zeros((B, steps, 3, H, W), device=device)\n",
    "            prediction_phys[:, :past_window] = data[:, :past_window, :3, :, :]\n",
    "\n",
    "            # 2. Boucle Autorégressive avec barre de progression interne\n",
    "            # desc=\"Rollout\" pour suivre l'avancement dans le temps (ex: 250 steps)\n",
    "            pbar_steps = tqdm(range(past_window, steps), desc=f\"Seq {s+1} steps\", leave=False, unit=\"step\")\n",
    "            \n",
    "            for i in pbar_steps:\n",
    "                # a. Préparer le conditionnement (9 frames passées)\n",
    "                history_phys = prediction_phys[:, i-past_window:i, :, :, :]\n",
    "                # Reynolds réel du dataset pour l'historique\n",
    "                history_reynolds = data[:, i-past_window:i, 3:4, :, :] \n",
    "                \n",
    "                # Fusion [B, 9, 4, 128, 64]\n",
    "                cond_frames = torch.cat([history_phys, history_reynolds], dim=2)\n",
    "                \n",
    "                # b. Paramètres scalaires (Reynolds)\n",
    "                u_past = params[:, i-past_window:i, :]\n",
    "                u_curr = params[:, i, :]\n",
    "\n",
    "                # c. Inférence par Diffusion (sampling)\n",
    "                result = model.sample(cond_frames, u_past, u_curr, num_steps=20, method='heun')\n",
    "                \n",
    "                # d. Stockage\n",
    "                prediction_phys[:, i] = result\n",
    "\n",
    "            all_gt.append(data[:, :, :3, :, :].cpu().numpy())\n",
    "            all_pred.append(prediction_phys.cpu().numpy())\n",
    "\n",
    "    # Recomposition des tenseurs\n",
    "    gt_phys = np.concatenate(all_gt, axis=0)\n",
    "    pred_phys = np.concatenate(all_pred, axis=0)\n",
    "\n",
    "    # 3. Dé-normalisation (Uniquement sur les 3 canaux physiques)\n",
    "    # Conversion des moyennes et stds en tenseurs numpy avec la bonne forme pour le calcul\n",
    "    normMean = testLoader.dataset.transform.normMean[:3].reshape(1, 1, 3, 1, 1)\n",
    "    normStd = testLoader.dataset.transform.normStd[:3].reshape(1, 1, 3, 1, 1)\n",
    "    \n",
    "    # Application de la formule : (x * std) + mean\n",
    "    gt_final = (gt_phys * normStd) + normMean\n",
    "    pred_final = (pred_phys * normStd) + normMean\n",
    "\n",
    "    print(\"\\n✅ Rollout complet terminé !\")\n",
    "    return gt_final, pred_final\n",
    "\n",
    "def calculate_mse(model, loader, device):\n",
    "    \"\"\"\n",
    "    Exécute le rollout sur un loader et calcule les MSE physiques.\n",
    "    \"\"\"\n",
    "    # 1. Obtenir les prédictions et la vérité terrain dé-normalisées\n",
    "    # On utilise 20 steps de diffusion pour un bon compromis précision/vitesse\n",
    "    gt_phys, pred_phys = run_rollout(model, loader, device)\n",
    "\n",
    "    # 2. Calcul des MSE par canal (VelX: 0, VelY: 1, Pression: 2)\n",
    "    mse_vx = np.mean((gt_phys[:, :, 0] - pred_phys[:, :, 0])**2)\n",
    "    mse_vy = np.mean((gt_phys[:, :, 1] - pred_phys[:, :, 1])**2)\n",
    "    mse_p  = np.mean((gt_phys[:, :, 2] - pred_phys[:, :, 2])**2)\n",
    "    \n",
    "    # MSE Globale\n",
    "    mse_global = (mse_vx + mse_vy + mse_p) / 3\n",
    "\n",
    "    print(f\"\\n--- Résultats ---\")\n",
    "    print(f\"MSE Globale : {mse_global}\")\n",
    "    print(f\"MSE Vel X   : {mse_vx}\")\n",
    "    print(f\"MSE Vel Y   : {mse_vy}\")\n",
    "    print(f\"MSE Pression: {mse_p}\")\n",
    "\n",
    "    return {\"global\": mse_global, \"vx\": mse_vx, \"vy\": mse_vy, \"p\": mse_p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Séquences:   0%|          | 0/5 [00:00<?, ?seq/s]/tmp/ipykernel_608835/2149731546.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "Total Séquences: 100%|██████████| 5/5 [02:08<00:00, 25.74s/seq]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Rollout complet terminé !\n",
      "\n",
      "--- Résultats ---\n",
      "MSE Globale : 0.07315181195735931\n",
      "MSE Vel X   : 0.006337182596325874\n",
      "MSE Vel Y   : 0.004584290087223053\n",
      "MSE Pression: 0.20853395760059357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_low = calculate_mse(model, test_loaders[0], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Séquences:   0%|          | 0/5 [00:00<?, ?seq/s]/tmp/ipykernel_608835/2149731546.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "Total Séquences: 100%|██████████| 5/5 [02:11<00:00, 26.28s/seq]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Rollout complet terminé !\n",
      "\n",
      "--- Résultats ---\n",
      "MSE Globale : 0.004852836020290852\n",
      "MSE Vel X   : 0.0004129851295147091\n",
      "MSE Vel Y   : 0.00035153795033693314\n",
      "MSE Pression: 0.013793985359370708\n",
      "{'global': np.float32(0.004852836), 'vx': np.float32(0.00041298513), 'vy': np.float32(0.00035153795), 'p': np.float32(0.013793985)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_high = calculate_mse(model, test_loaders[1], device)\n",
    "print(res_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Séquences:   0%|          | 0/1 [00:00<?, ?seq/s]/tmp/ipykernel_608835/2149731546.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "Total Séquences: 100%|██████████| 1/1 [02:04<00:00, 124.17s/seq]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Rollout complet terminé !\n",
      "\n",
      "--- Résultats ---\n",
      "MSE Globale : 0.11326124519109726\n",
      "MSE Vel X   : 0.010605995543301105\n",
      "MSE Vel Y   : 0.0082953330129385\n",
      "MSE Pression: 0.3208824098110199\n",
      "{'global': np.float32(0.113261245), 'vx': np.float32(0.010605996), 'vy': np.float32(0.008295333), 'p': np.float32(0.3208824)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_vac = calculate_mse(model, test_loaders[2], device)\n",
    "print(res_vac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "sequence_idx = 0         # Quelle simulation du batch afficher\n",
    "field = 2                # 0: VelX, 1: VelY, 2: Pression\n",
    "# On choisit des étapes significatives sur les 241 disponibles\n",
    "timeSteps = [0, 79, 159, 239] \n",
    "timeSteps = [1, 20, 40, 60] \n",
    "\n",
    "# 1. Extraction des données (B, T, C, H, W)\n",
    "# GT : On prend la séquence, les pas de temps et le canal choisi\n",
    "gt_vis = gt[sequence_idx, timeSteps, field]      # Shape: (4, 128, 64)\n",
    "\n",
    "# PRED : Idem pour la prédiction\n",
    "pred_vis = pred[sequence_idx, timeSteps, field]  # Shape: (4, 128, 64)\n",
    "\n",
    "# On les combine : Ligne 0 = GT, Ligne 1 = Prediction\n",
    "gt_pred_combined = np.stack([gt_vis, pred_vis], axis=0) # Shape: (2, 4, 128, 64)\n",
    "\n",
    "# 2. Création de la figure\n",
    "nrows, ncols = gt_pred_combined.shape[0], gt_pred_combined.shape[1]\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows, \n",
    "    ncols=ncols, \n",
    "    figsize=(ncols * 3, nrows * 3.5), # Ajusté pour le format 128x64\n",
    "    dpi=120, \n",
    "    squeeze=False\n",
    ")\n",
    "\n",
    "# 3. Boucle d'affichage\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        ax = axs[i, j]\n",
    "        \n",
    "        # Données à afficher\n",
    "        data = gt_pred_combined[i, j]\n",
    "        \n",
    "        # .T (Transpose) pour mettre le 128 en largeur\n",
    "        # origin='lower' pour avoir le bas de la soufflerie en bas de l'image\n",
    "        im = ax.imshow(data.T, interpolation=\"catrom\", cmap=\"viridis\", origin='lower')\n",
    "        \n",
    "        # Titres de colonnes (Temps)\n",
    "        if i == 0:\n",
    "            ax.set_title(f\"Step {timeSteps[j]}\", fontsize=10, pad=10)\n",
    "            \n",
    "        # Labels de lignes\n",
    "        if j == 0:\n",
    "            label = \"Ground Truth\" if i == 0 else \"Jit Pred\"\n",
    "            ax.set_ylabel(label, fontsize=11, fontweight='bold')\n",
    "        \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9292796,
     "sourceId": 14549409,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "jit2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
